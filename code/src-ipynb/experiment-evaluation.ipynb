{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333830a6-c203-4276-8c9f-e6bcfe4ad787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad429b3-f236-4bb6-a707-569206d9a309",
   "metadata": {},
   "source": [
    "### Predicting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42604acd-340f-4d86-8a90-e483f0323fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "sys.path.insert(0, \"../../src-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974169db-f674-402b-9974-0e1835f30b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from track_1_kp_matching import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076715e9-5efe-45aa-9a35-ae7e1913940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, LoggingHandler, losses, models, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97820cc-f2f1-4e1f-8eec-52676ce48570",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('path_to_validatoin_file', index_col=0)\n",
    "valid_keypoints_df = pd.read_csv('path_to_the_validation_keypoints')\n",
    "valid_arguments_df = pd.read_csv('path_to_the_validation_arguments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793ef82f-bd93-4005-9c3c-06b446844dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_argument_with_keypoints(result, kp_dict, arg_dict):\n",
    "    \n",
    "    for arg, arg_embedding in arg_dict.items():\n",
    "        result[arg] = {}\n",
    "        for kp, kp_embedding in kp_dict.items():\n",
    "            result[arg][kp] = util.pytorch_cos_sim(arg_embedding, kp_embedding).item()\n",
    "        \n",
    "        #Applying softmax\n",
    "        kp_scores = list(result[arg].items())\n",
    "        kp_ids, kp_scores = zip(*kp_scores)\n",
    "        result[arg] = {kp_id:score for kp_id, score in zip(kp_ids, kp_scores)}\n",
    "        \n",
    "\n",
    "    return result\n",
    "\n",
    "def predict(model, argument_df, keypoint_df, output_path, append_topic=False):\n",
    "    argument_keypoints = {}\n",
    "    for topic in argument_df.topic.unique():\n",
    "        for stance in [-1, 1]:\n",
    "            topic_keypoints_ids = keypoint_df[(keypoint_df.topic==topic) & (keypoint_df.stance==stance)]['key_point_id'].tolist()\n",
    "            topic_keypoints = keypoint_df[(keypoint_df.topic==topic) & (keypoint_df.stance==stance)]['key_point'].tolist()\n",
    "            if append_topic:\n",
    "                topic_keypoints = [topic + ' <SEP> ' + x for x in topic_keypoints]\n",
    "                \n",
    "            topic_keypoints_embeddings = model.encode(topic_keypoints)\n",
    "            topic_kp_embed = dict(zip(topic_keypoints_ids, topic_keypoints_embeddings))\n",
    "\n",
    "            topic_arguments_ids = argument_df[(argument_df.topic==topic) & (argument_df.stance==stance)]['arg_id'].tolist()\n",
    "            topic_arguments = argument_df[(argument_df.topic==topic) & (argument_df.stance==stance)]['argument'].tolist()\n",
    "            topic_arguments_embeddings = model.encode(topic_arguments)\n",
    "            topic_arg_embed= dict(zip(topic_arguments_ids, topic_arguments_embeddings))\n",
    "\n",
    "            argument_keypoints = match_argument_with_keypoints(argument_keypoints, topic_kp_embed, topic_arg_embed)\n",
    "    \n",
    "    json.dump(argument_keypoints, open(output_path, 'w'))\n",
    "    \n",
    "    return argument_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa80983-6afd-4641-9c99-ed1c2753b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    'path_to_model1',\n",
    "    'path_to_model2',\n",
    "    '...',\n",
    "    'path_to_modeln',\n",
    "]\n",
    "\n",
    "pred_output_path = 'path_to_folder_where_the_prediction_files_need_to_be_saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1ffaac-01ad-49e9-ab52-a1a2cc6381a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_and_evaluate(argument_df, keypoint_df, gold_data_dir, subset_name):\n",
    "    pred_df = {}\n",
    "    for model_path in models_list:\n",
    "        append_topic= 'topic_added' in model_path\n",
    "        #Predict\n",
    "        model = SentenceTransformer(model_path)\n",
    "        model_name = model_path.split('/')[-1]\n",
    "        predictions_file = pred_output_path+model_name+ '-' + subset_name + '-preds.json'\n",
    "        json_preds = predict(model, argument_df, keypoint_df, predictions_file, append_topic)\n",
    "\n",
    "        #Evaluate\n",
    "        arg_df, kp_df, labels_df = load_kpm_data(gold_data_dir, subset=subset_name)\n",
    "        merged_df = get_predictions(predictions_file, labels_df, arg_df)\n",
    "        print('Evaluating {}:'.format(model_name))\n",
    "        evaluate_predictions(merged_df)\n",
    "        \n",
    "        pred_df[model_name] = merged_df\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d94139e0-a8ef-41fb-bff0-1bceac93f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bert-base-uncased-kp_as_anchor_topic_added_max_20_neg_samples-2021-05-27_11-20-47:\n",
      "mAP strict= 0.8123734434931347 ; mAP relaxed = 0.9333860691751199\n"
     ]
    }
   ],
   "source": [
    "pred_dfs = predict_and_evaluate(valid_arguments_df, valid_keypoints_df,  '../../data', 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006577c-a381-41f3-b80a-daff7d12558d",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c756a874-654c-4eb1-b1c3-0c6b04b27015",
   "metadata": {},
   "source": [
    "### Predicting on the final test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abcbede8-4493-4424-a0ae-156e3c29b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arg_df = pd.read_csv('../../KPA_2021_shared_task/test_data/arguments_test.csv')\n",
    "test_keypoints_df = pd.read_csv('../../KPA_2021_shared_task/test_data/key_points_test.csv')\n",
    "test_pred_keypoints_df = pd.read_csv('path_to_the_generated_keypoints_of_pagerank_algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cbeb330-4750-4145-985c-0533bbbb6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_keypoints_aspect_df = pd.read_csv('../../track-2-keypoint-extraction/test_split_with_aspects-key_points-x10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cc608a3-b52f-4dd5-8d27-16304082a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('path_to_the_final_model')\n",
    "json_preds = predict(model, test_arg_df, test_keypoints_df, 'output_of_the_predicition', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ca289-6da2-4568-b68c-4799351621b4",
   "metadata": {},
   "source": [
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
