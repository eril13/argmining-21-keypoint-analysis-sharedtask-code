{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Let's do the normal evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP strict= 0.844355603203168 ; mAP relaxed = 0.947050810808719\n"
     ]
    }
   ],
   "source": [
    "! python3 /workspace/project_git/keypoint-analysis-sharedtask/src-py/track_1_kp_matching.py /workspace/project_git/keypoint-analysis-sharedtask/data /workspace/ceph_data/data-in-progress/data-research/arguana/arg-generation/keypoint-analysis-sharedtask/siamese-data/preds/bert-base-uncased-kp_as_anchor-2021-05-24_15-58-35-our_valid-preds.json our_valid"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Let's trick the metric now\n",
    " - Load the evaluation code\n",
    " - Change the code such that we use only the top 25% of our predictions for each topic stance pair\n",
    " - Store the arguments used\n",
    " - Delete all the other arguments from our prediction file\n",
    " - Save the new prediction file\n",
    " - Do the normal evaluation again"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_average_precision(df, label_column):\n",
    "    precisions = [get_ap(group, label_column) for _, group in df.groupby([\"topic\", \"stance\"])]\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def evaluate_predictions(merged_df):\n",
    "    mAP_strict = calc_mean_average_precision(merged_df, \"label_strict\")\n",
    "    mAP_relaxed = calc_mean_average_precision(merged_df, \"label_relaxed\")\n",
    "    print(f\"mAP strict= {mAP_strict} ; mAP relaxed = {mAP_relaxed}\")\n",
    "\n",
    "def load_kpm_data(gold_data_dir, subset):\n",
    "    arguments_file = os.path.join(gold_data_dir, f\"arguments_{subset}.csv\")\n",
    "    key_points_file = os.path.join(gold_data_dir, f\"key_points_{subset}.csv\")\n",
    "    labels_file = os.path.join(gold_data_dir, f\"labels_{subset}.csv\")\n",
    "\n",
    "    arguments_df = pd.read_csv(arguments_file)\n",
    "    key_points_df = pd.read_csv(key_points_file)\n",
    "    labels_file_df = pd.read_csv(labels_file)\n",
    "\n",
    "    return arguments_df, key_points_df, labels_file_df\n",
    "\n",
    "\n",
    "def get_predictions(predictions_file, labels_df, arg_df):\n",
    "    arg_df = arg_df[[\"arg_id\", \"topic\", \"stance\"]]\n",
    "    predictions_df = load_predictions(predictions_file)\n",
    "    #make sure each arg_id has a prediction\n",
    "    predictions_df = pd.merge(arg_df, predictions_df, how=\"left\", on=\"arg_id\")\n",
    "\n",
    "    #handle arguements with no matching key point\n",
    "    predictions_df[\"key_point_id\"] = predictions_df[\"key_point_id\"].fillna(\"dummy_id\")\n",
    "    predictions_df[\"score\"] = predictions_df[\"score\"].fillna(0)\n",
    "\n",
    "    #merge each argument with the gold labels\n",
    "    merged_df = pd.merge(predictions_df, labels_df, how=\"left\", on=[\"arg_id\", \"key_point_id\"])\n",
    "\n",
    "    merged_df.loc[merged_df['key_point_id'] == \"dummy_id\", 'label'] = 0\n",
    "    merged_df[\"label_strict\"] = merged_df[\"label\"].fillna(0)\n",
    "    merged_df[\"label_relaxed\"] = merged_df[\"label\"].fillna(1)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "this method chooses the best key point for each argument\n",
    "and generates a dataframe with the matches and scores\n",
    "\"\"\"\n",
    "def load_predictions(predictions_dir):\n",
    "    arg =[]\n",
    "    kp = []\n",
    "    scores = []\n",
    "    with open(predictions_dir, \"r\") as f_in:\n",
    "        res = json.load(f_in)\n",
    "        for arg_id, kps in res.items():\n",
    "            best_kp = max(kps.items(), key=lambda x: x[1])\n",
    "            arg.append(arg_id)\n",
    "            kp.append(best_kp[0])\n",
    "            scores.append(best_kp[1])\n",
    "        return pd.DataFrame({\"arg_id\" : arg, \"key_point_id\": kp, \"score\": scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_dir = \"/workspace/project_git/keypoint-analysis-sharedtask/data\"\n",
    "predictions_file = \"/workspace/ceph_data/data-in-progress/data-research/arguana/arg-generation/keypoint-analysis-sharedtask/siamese-data/preds/bert-base-uncased-kp_as_anchor-2021-05-24_15-58-35-our_valid-preds.json\"\n",
    "subset_name = \"our_valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         arg_4_0   arg_4_1   arg_4_3   arg_4_4   arg_4_5   arg_4_7   arg_4_9  \\\n",
       "kp_4_0 -0.113464  0.050940 -0.027673  0.126287  0.339497  0.210822  0.342209   \n",
       "kp_4_1  0.833244  0.116367 -0.400722  0.130977 -0.081358 -0.195857  0.158396   \n",
       "kp_4_2  0.000899  0.707487  0.422451  0.708077 -0.067458  0.657558  0.000632   \n",
       "kp_4_3 -0.082468  0.079495  0.775373  0.159886  0.238906  0.208040 -0.002771   \n",
       "kp_4_4  0.036106  0.001145  0.176084  0.181782  0.618537  0.414745  0.389428   \n",
       "\n",
       "        arg_4_10  arg_4_11  arg_4_12  ...  arg_15_224  arg_15_225  arg_15_132  \\\n",
       "kp_4_0 -0.199425  0.454778  0.408215  ...         NaN         NaN         NaN   \n",
       "kp_4_1  0.970414 -0.230579 -0.154799  ...         NaN         NaN         NaN   \n",
       "kp_4_2 -0.049008  0.277821  0.409436  ...         NaN         NaN         NaN   \n",
       "kp_4_3 -0.338597  0.226339  0.001494  ...         NaN         NaN         NaN   \n",
       "kp_4_4  0.012436  0.665420  0.391511  ...         NaN         NaN         NaN   \n",
       "\n",
       "        arg_15_156  arg_15_197  arg_15_214  arg_15_215  arg_15_222  \\\n",
       "kp_4_0         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_1         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_2         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_3         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_4         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        arg_15_120  arg_15_159  \n",
       "kp_4_0         NaN         NaN  \n",
       "kp_4_1         NaN         NaN  \n",
       "kp_4_2         NaN         NaN  \n",
       "kp_4_3         NaN         NaN  \n",
       "kp_4_4         NaN         NaN  \n",
       "\n",
       "[5 rows x 653 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>arg_4_0</th>\n      <th>arg_4_1</th>\n      <th>arg_4_3</th>\n      <th>arg_4_4</th>\n      <th>arg_4_5</th>\n      <th>arg_4_7</th>\n      <th>arg_4_9</th>\n      <th>arg_4_10</th>\n      <th>arg_4_11</th>\n      <th>arg_4_12</th>\n      <th>...</th>\n      <th>arg_15_224</th>\n      <th>arg_15_225</th>\n      <th>arg_15_132</th>\n      <th>arg_15_156</th>\n      <th>arg_15_197</th>\n      <th>arg_15_214</th>\n      <th>arg_15_215</th>\n      <th>arg_15_222</th>\n      <th>arg_15_120</th>\n      <th>arg_15_159</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>kp_4_0</th>\n      <td>-0.113464</td>\n      <td>0.050940</td>\n      <td>-0.027673</td>\n      <td>0.126287</td>\n      <td>0.339497</td>\n      <td>0.210822</td>\n      <td>0.342209</td>\n      <td>-0.199425</td>\n      <td>0.454778</td>\n      <td>0.408215</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_1</th>\n      <td>0.833244</td>\n      <td>0.116367</td>\n      <td>-0.400722</td>\n      <td>0.130977</td>\n      <td>-0.081358</td>\n      <td>-0.195857</td>\n      <td>0.158396</td>\n      <td>0.970414</td>\n      <td>-0.230579</td>\n      <td>-0.154799</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_2</th>\n      <td>0.000899</td>\n      <td>0.707487</td>\n      <td>0.422451</td>\n      <td>0.708077</td>\n      <td>-0.067458</td>\n      <td>0.657558</td>\n      <td>0.000632</td>\n      <td>-0.049008</td>\n      <td>0.277821</td>\n      <td>0.409436</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_3</th>\n      <td>-0.082468</td>\n      <td>0.079495</td>\n      <td>0.775373</td>\n      <td>0.159886</td>\n      <td>0.238906</td>\n      <td>0.208040</td>\n      <td>-0.002771</td>\n      <td>-0.338597</td>\n      <td>0.226339</td>\n      <td>0.001494</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_4</th>\n      <td>0.036106</td>\n      <td>0.001145</td>\n      <td>0.176084</td>\n      <td>0.181782</td>\n      <td>0.618537</td>\n      <td>0.414745</td>\n      <td>0.389428</td>\n      <td>0.012436</td>\n      <td>0.665420</td>\n      <td>0.391511</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 653 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "manipulate_predictions_df = pd.read_json(predictions_file)\n",
    "manipulate_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_in_top25 = []\n",
    "def get_ap(df, label_column, top_percentile=0.5):\n",
    "    global args_in_top25\n",
    "    top = int(len(df)*top_percentile)\n",
    "    df = df.sort_values('score', ascending=False).head(top)\n",
    "\n",
    "    top = int(len(df)*0.5)\n",
    "    df = df.sort_values('score', ascending=False).head(top)\n",
    "\n",
    "    args_in_top25 += df['arg_id'].tolist()\n",
    "\n",
    "    return average_precision_score(y_true=df[label_column].tolist(), y_score=df[\"score\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP strict= 0.9126890639942158 ; mAP relaxed = 0.966407574792025\n"
     ]
    }
   ],
   "source": [
    "arg_df, kp_df, labels_df = load_kpm_data(gold_data_dir, subset=subset_name)\n",
    "merged_df = get_predictions(predictions_file, labels_df, arg_df)\n",
    "evaluate_predictions(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         arg_4_0   arg_4_1   arg_4_3   arg_4_4   arg_4_5   arg_4_7   arg_4_9  \\\n",
       "kp_4_0 -0.113464  0.050940 -0.027673  0.126287  0.339497  0.210822  0.342209   \n",
       "kp_4_1  0.833244  0.116367 -0.400722  0.130977 -0.081358 -0.195857  0.158396   \n",
       "kp_4_2  0.000899  0.707487  0.422451  0.708077 -0.067458  0.657558  0.000632   \n",
       "kp_4_3 -0.082468  0.079495  0.775373  0.159886  0.238906  0.208040 -0.002771   \n",
       "kp_4_4  0.036106  0.001145  0.176084  0.181782  0.618537  0.414745  0.389428   \n",
       "\n",
       "        arg_4_10  arg_4_11  arg_4_12  ...  arg_15_224  arg_15_225  arg_15_132  \\\n",
       "kp_4_0 -0.199425  0.454778  0.408215  ...         NaN         NaN         NaN   \n",
       "kp_4_1  0.970414 -0.230579 -0.154799  ...         NaN         NaN         NaN   \n",
       "kp_4_2 -0.049008  0.277821  0.409436  ...         NaN         NaN         NaN   \n",
       "kp_4_3 -0.338597  0.226339  0.001494  ...         NaN         NaN         NaN   \n",
       "kp_4_4  0.012436  0.665420  0.391511  ...         NaN         NaN         NaN   \n",
       "\n",
       "        arg_15_156  arg_15_197  arg_15_214  arg_15_215  arg_15_222  \\\n",
       "kp_4_0         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_1         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_2         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_3         NaN         NaN         NaN         NaN         NaN   \n",
       "kp_4_4         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        arg_15_120  arg_15_159  \n",
       "kp_4_0         NaN         NaN  \n",
       "kp_4_1         NaN         NaN  \n",
       "kp_4_2         NaN         NaN  \n",
       "kp_4_3         NaN         NaN  \n",
       "kp_4_4         NaN         NaN  \n",
       "\n",
       "[5 rows x 653 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>arg_4_0</th>\n      <th>arg_4_1</th>\n      <th>arg_4_3</th>\n      <th>arg_4_4</th>\n      <th>arg_4_5</th>\n      <th>arg_4_7</th>\n      <th>arg_4_9</th>\n      <th>arg_4_10</th>\n      <th>arg_4_11</th>\n      <th>arg_4_12</th>\n      <th>...</th>\n      <th>arg_15_224</th>\n      <th>arg_15_225</th>\n      <th>arg_15_132</th>\n      <th>arg_15_156</th>\n      <th>arg_15_197</th>\n      <th>arg_15_214</th>\n      <th>arg_15_215</th>\n      <th>arg_15_222</th>\n      <th>arg_15_120</th>\n      <th>arg_15_159</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>kp_4_0</th>\n      <td>-0.113464</td>\n      <td>0.050940</td>\n      <td>-0.027673</td>\n      <td>0.126287</td>\n      <td>0.339497</td>\n      <td>0.210822</td>\n      <td>0.342209</td>\n      <td>-0.199425</td>\n      <td>0.454778</td>\n      <td>0.408215</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_1</th>\n      <td>0.833244</td>\n      <td>0.116367</td>\n      <td>-0.400722</td>\n      <td>0.130977</td>\n      <td>-0.081358</td>\n      <td>-0.195857</td>\n      <td>0.158396</td>\n      <td>0.970414</td>\n      <td>-0.230579</td>\n      <td>-0.154799</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_2</th>\n      <td>0.000899</td>\n      <td>0.707487</td>\n      <td>0.422451</td>\n      <td>0.708077</td>\n      <td>-0.067458</td>\n      <td>0.657558</td>\n      <td>0.000632</td>\n      <td>-0.049008</td>\n      <td>0.277821</td>\n      <td>0.409436</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_3</th>\n      <td>-0.082468</td>\n      <td>0.079495</td>\n      <td>0.775373</td>\n      <td>0.159886</td>\n      <td>0.238906</td>\n      <td>0.208040</td>\n      <td>-0.002771</td>\n      <td>-0.338597</td>\n      <td>0.226339</td>\n      <td>0.001494</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>kp_4_4</th>\n      <td>0.036106</td>\n      <td>0.001145</td>\n      <td>0.176084</td>\n      <td>0.181782</td>\n      <td>0.618537</td>\n      <td>0.414745</td>\n      <td>0.389428</td>\n      <td>0.012436</td>\n      <td>0.665420</td>\n      <td>0.391511</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 653 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "manipulate_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_predictions_df.drop(list(set(manipulate_predictions_df.columns) - set(args_in_top25)), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_predictions_df = manipulate_predictions_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_predictions_df.to_json('/workspace/trash/manipulated_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mAP strict= 0.9126890639942158 ; mAP relaxed = 0.966407574792025\n"
     ]
    }
   ],
   "source": [
    "! python3 /workspace/project_git/keypoint-analysis-sharedtask/src-py/track_1_kp_matching.py /workspace/project_git/keypoint-analysis-sharedtask/data /workspace/trash/manipulated_scores.json our_valid"
   ]
  },
  {
   "source": [
    "## Profit!!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}